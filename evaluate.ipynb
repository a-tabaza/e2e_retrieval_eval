{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end retrieval evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch Wikipedia Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\Abdulrahman\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "from typing import List\n",
    "import concurrent.futures\n",
    "\n",
    "import ir_measures\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from ir_measures import *\n",
    "from openai import OpenAI\n",
    "from cohere import ClientV2\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "from usearch.index import Index\n",
    "from mediawiki import MediaWiki\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia = MediaWiki(lang=\"ar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = wikipedia.search(\"الثورة التونسية\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = [wikipedia.page(result) for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_full = [\n",
    "    {\n",
    "        \"id\": page.pageid,\n",
    "        \"text\": page.content,\n",
    "        \"meta\": {\"title\": page.title, \"summary\": page.summarize(chars=256)},\n",
    "    }\n",
    "    for page in pages\n",
    "    if page\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(pages_full, open(\"data.json\", \"w\", encoding=\"utf-8\"), ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\Abdulrahman\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdulrahman\\Desktop\\rag_experiments\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from chunking import ClusterSemanticChunker\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = ClusterSemanticChunker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
      "[ClusterSemanticChunker] Embedding sentences: 100%|██████████| 7/7 [00:15<00:00,  2.24s/it]\n",
      "[ClusterSemanticChunker] Calculating reward: 100%|██████████| 621/621 [00:00<00:00, 28205.78it/s]\n",
      "[ClusterSemanticChunker] Embedding sentences: 100%|██████████| 7/7 [00:13<00:00,  1.96s/it]\n",
      "[ClusterSemanticChunker] Calculating reward: 100%|██████████| 587/587 [00:00<00:00, 32600.09it/s]\n",
      "[ClusterSemanticChunker] Embedding sentences: 100%|██████████| 19/19 [00:41<00:00,  2.16s/it]\n",
      "[ClusterSemanticChunker] Calculating reward: 100%|██████████| 1757/1757 [00:00<00:00, 42565.16it/s]\n",
      "[ClusterSemanticChunker] Embedding sentences: 100%|██████████| 4/4 [00:07<00:00,  1.96s/it]\n",
      "[ClusterSemanticChunker] Calculating reward: 100%|██████████| 367/367 [00:00<00:00, 45901.58it/s]\n",
      "[ClusterSemanticChunker] Embedding sentences: 100%|██████████| 8/8 [00:15<00:00,  1.88s/it]\n",
      "[ClusterSemanticChunker] Calculating reward: 100%|██████████| 700/700 [00:00<00:00, 41136.76it/s]\n",
      "[ClusterSemanticChunker] Embedding sentences: 100%|██████████| 9/9 [00:16<00:00,  1.88s/it]\n",
      "[ClusterSemanticChunker] Calculating reward: 100%|██████████| 803/803 [00:00<00:00, 40694.34it/s]\n",
      "[ClusterSemanticChunker] Embedding sentences: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "[ClusterSemanticChunker] Calculating reward: 100%|██████████| 67/67 [00:00<00:00, 22336.73it/s]\n",
      "[ClusterSemanticChunker] Embedding sentences: 100%|██████████| 3/3 [00:04<00:00,  1.62s/it]\n",
      "[ClusterSemanticChunker] Calculating reward: 100%|██████████| 218/218 [00:00<00:00, 36417.01it/s]\n",
      "[ClusterSemanticChunker] Embedding sentences: 100%|██████████| 7/7 [00:14<00:00,  2.02s/it]\n",
      "[ClusterSemanticChunker] Calculating reward: 100%|██████████| 650/650 [00:00<00:00, 25001.58it/s]\n",
      "[ClusterSemanticChunker] Embedding sentences: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "[ClusterSemanticChunker] Calculating reward: 100%|██████████| 22/22 [00:00<00:00, 22038.38it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in pages_full:\n",
    "    doc[\"chunks\"] = text_splitter.split_text(doc[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "for doc in pages_full:\n",
    "    for chunk in doc[\"chunks\"]:\n",
    "        chunk = {\n",
    "            \"id\": doc[\"id\"],\n",
    "            \"chunk_id\": str(uuid4()),\n",
    "            \"text\": chunk,\n",
    "            \"meta\": doc[\"meta\"],\n",
    "        }\n",
    "        chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(chunks, open(\"chunks.json\", \"w\", encoding=\"utf-8\"), ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query(BaseModel):\n",
    "    \"\"\"A query about a passage.\"\"\"\n",
    "    queries: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(passage: str) -> Query:\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Generate queries in Arabic about the following passage. Provided are also metadata about the document the passage is from.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "            Title:\n",
    "            {passage[\"meta\"][\"title\"]}\n",
    "\n",
    "            Summary of the document:\n",
    "            {passage[\"meta\"][\"summary\"]}\n",
    "             \n",
    "            Passage:\n",
    "            {passage[\"text\"]}\n",
    "            \"\"\"},\n",
    "        ],\n",
    "        response_format=Query,\n",
    "    )\n",
    "    return completion.choices[0].message.parsed.queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chunk in tqdm(chunks):\n",
    "#     chunk[\"queries\"] = generate_queries(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1982/1982 [04:56<00:00,  6.68it/s]\n"
     ]
    }
   ],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(generate_queries, chunk) for chunk in chunks]\n",
    "    for future in tqdm(futures, total=len(chunks)):\n",
    "        result = future.result()\n",
    "        chunk = chunks[futures.index(future)]\n",
    "        chunk[\"queries\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(chunks, open(\"chunks_with_queries.json\", \"w\", encoding=\"utf-8\"), ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = []\n",
    "for chunk in chunks:\n",
    "    for query in chunk['queries']:\n",
    "        queries.append(query)\n",
    "queries = list(set(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_mapping = {query: str(uuid4()) for query in queries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = []\n",
    "for chunk in chunks:\n",
    "    for query in chunk['queries']:\n",
    "        ground_truth.append({\n",
    "            \"query_id\": queries_mapping[query],\n",
    "            \"chunk_id\": chunk['chunk_id'],\n",
    "            \"ground_truth\": chunk['text'],\n",
    "            \"query\": query,\n",
    "            \"meta\": chunk['meta']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(ground_truth, open('query_with_ground_truth.json', 'w', encoding=\"utf-8\"), indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"qrels.txt\", \"wt\") as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter=' ')\n",
    "    for gt in ground_truth:\n",
    "        tsv_writer.writerow([gt[\"query_id\"], \"0\", gt[\"chunk_id\"], \"1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_key_mapping = {\n",
    "    chunk[\"chunk_id\"]: idx for idx, chunk in enumerate(chunks)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(chunk_key_mapping, open(\"chunk_key_mapping.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = ClientV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_document(chunk):\n",
    "    full_text = chunk[\"text\"]\n",
    "    embedding_text = f\"\"\"\n",
    "    عنوان المستند:\n",
    "    {chunk[\"meta\"][\"title\"]}\n",
    "    ملخص المستند:\n",
    "    {chunk[\"meta\"][\"summary\"]}\n",
    "\n",
    "    الفقرة:\n",
    "    {full_text}\n",
    "    \"\"\"\n",
    "    return np.array(co.embed(texts=[embedding_text], \n",
    "                             model=\"embed-multilingual-v3.0\", \n",
    "                             input_type=\"search_document\", \n",
    "                             embedding_types=['float']).embeddings.float_).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chunk in tqdm(chunks):\n",
    "#     chunk[\"embedding\"] = embed_document(chunk).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1982/1982 [00:40<00:00, 49.28it/s]\n"
     ]
    }
   ],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = {executor.submit(embed_document, chunk): chunk for chunk in chunks}\n",
    "    for future in tqdm(concurrent.futures.as_completed(futures), total=len(chunks)):\n",
    "        chunk = futures[future]\n",
    "        chunk[\"embedding\"] = future.result().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(chunks, open(\"chunks_with_queries_and_embeddings.json\", \"w\", encoding=\"utf-8\"), indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = json.load(open(\"query_with_ground_truth.json\", \"r\", encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_query(query):\n",
    "    return np.array(co.embed(texts=[query[\"query\"]], \n",
    "                             model=\"embed-multilingual-v3.0\", \n",
    "                             input_type=\"search_query\", \n",
    "                             embedding_types=['float']).embeddings.float_).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for query in tqdm(queries):\n",
    "#     query[\"embedding\"] = embed_query(query).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10529/10529 [03:29<00:00, 50.16it/s]\n"
     ]
    }
   ],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = {executor.submit(embed_query, query): query for query in queries}\n",
    "    for future in tqdm(concurrent.futures.as_completed(futures), total=len(queries)):\n",
    "        query = futures[future]\n",
    "        query[\"embedding\"] = future.result().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(queries, open(\"query_with_ground_truth_and_embeddings.json\", \"w\", encoding=\"utf-8\"), indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = json.load(open('chunks_with_queries_and_embeddings.json', encoding=\"utf-8\"))\n",
    "chunk_id_to_key = json.load(open('chunk_key_mapping.json'))\n",
    "key_to_chunk_id = {v: k for k, v in chunk_id_to_key.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_index = Index(ndim=1024, metric='cos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 1979, 1980, 1981], dtype=uint64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_index.add([i for i in range(len(chunks))], np.array([chunk['embedding'] for chunk in chunks]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_index.save(\"chunks.usearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = json.load(open(\"query_with_ground_truth_and_embeddings.json\"))\n",
    "chunk_id_to_key = json.load(open('chunk_key_mapping.json'))\n",
    "key_to_chunk_id = {v: k for k, v in chunk_id_to_key.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_index = Index(ndim=1024, metric='cos')\n",
    "chunks_index.load(\"chunks.usearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, k=10):\n",
    "    query_embedding = np.array(query[\"embedding\"]).reshape(1, -1)\n",
    "    matches = chunks_index.search(query_embedding, k)\n",
    "    doc_ids = [key_to_chunk_id[key] for key in matches.keys.tolist()]\n",
    "    scores = matches.distances.tolist()\n",
    "    similarities = [1 - score for score in scores]\n",
    "    run_entries = zip(doc_ids, similarities)\n",
    "    return [ir_measures.ScoredDoc(str(query[\"query_id\"]), str(entry[0]), entry[1]) for entry in run_entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10529/10529 [00:02<00:00, 4458.75it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for query in tqdm(queries):\n",
    "    results.extend(retrieve(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{R@5: 0.40713114018569113,\n",
       " P@1: 0.23096242716495882,\n",
       " R@3: 0.35321323325392046,\n",
       " P@5: 0.0820373719107945,\n",
       " R@1: 0.22994704210798242,\n",
       " P@3: 0.11837787154242964}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels = ir_measures.read_trec_qrels('qrels.txt')\n",
    "ir_measures.calc_aggregate([P@1, P@3, P@5, R@1, R@3, R@5], qrels, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
